{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.3 Introduction to Information Retrieval\n",
    "\n",
    "Here we work with a data set scraped from eBay.  The data contains 9895 item titles and descriptions.\n",
    "\n",
    "First we load the data file and _normalise_ the text - removing certain characters and converting to lower case.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import re\n",
    "\n",
    "with open(\"data/bike-items.txt\") as f:\n",
    "    r = csv.reader(f, delimiter=',', quotechar='\"')\n",
    "    rgx = re.compile(r'\\b[a-zA-Z]+\\b') \n",
    "    docs = [ (' '.join(re.findall(rgx, x[0])).lower(), ' '.join(re.findall(rgx, x[1])).lower())  \\\n",
    "            for i,x in enumerate(r) if i > 1 ]\n",
    "    \n",
    "print(docs[0][0],docs[0][1])\n",
    "\n",
    "items_t = [ d[0] for d in docs ] # item titles\n",
    "items_d = [ d[1] for d in docs ] # item descriptions\n",
    "items_i = range(0, len(items_t)) # item id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise Set 1 - Term Frequency\n",
    "\n",
    "Let's start with the first 5 item titles from our corpus:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "corpus = items_t[0:5]\n",
    "print(corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will start by computing the frequency of terms in the *entire* corpus.  We will do this by enumerating over the corpus of documents, tokenizing the documents and counting the frequency of tokens.   The easiest way is to build a python dictionary where the key is the token and the value is the count.  You can review python dictionaries in the [docs](https://docs.python.org/2/tutorial/datastructures.html).\n",
    "\n",
    "<img src='files/resources/ic_assignment_black_24dp_2x.png' align='left'>\n",
    "Here is a part completed code snippet to compute term frequency.  \n",
    "Complete this code to correctly populate the term frequency dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tf = {}\n",
    "for doc in corpus:\n",
    "    for word in doc.split():\n",
    "        # << COMPUTE TERM FREQUENCY USING DICTIONARY >> \n",
    "        # IF word IN tf THEN tf[word] = tf[word] + 1\n",
    "        # ELSE tf[word] = 1\n",
    "        # CODE HERE >>\n",
    "        \n",
    "\n",
    "print(tf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can simplify by using a [Counter](https://docs.python.org/2/library/collections.html#collections.Counter) rather than a dictionary.  The `Counter` automatically checks for the existence of the key in the collection.  This simplifies our code.\n",
    "\n",
    "<img src='files/resources/ic_assignment_black_24dp_2x.png' align='left'> \n",
    "Take a look at the docs for the `Counter` collection.  \n",
    "Complete this function definition to compute term frequency using the `Counter`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def get_tf(corpus):\n",
    "    tf = Counter()\n",
    "    for doc in corpus:\n",
    "        for word in doc.split():\n",
    "            # << COMPUTE TERM FREQUENCY USING DICTIONARY >> \n",
    "            # IF word IN tf THEN tf[word] = tf[word] + 1\n",
    "            # ELSE tf[word] = 1\n",
    "            # CODE HERE >>\n",
    "            \n",
    "            \n",
    "    return tf\n",
    "\n",
    "tf = get_tf(corpus)\n",
    "print(tf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Counter does not give us a speed advantage - since it does more work than a Dictionary.   For these tiny data sets we do not see any difference - however in Python 3 it is faster than a default dictionary.  Often times best way to test performance is to time code execution.\n",
    "\n",
    "<img src='files/resources/ic_info_outline_black_24dp_2x.png' align='left'> \n",
    "We should get used to thinking about performance.   \n",
    "We can use the Jupyter Notebook [magics](http://nbviewer.jupyter.org/github/ipython/ipython/blob/1.x/examples/notebooks/Cell%20Magics.ipynb) to time the execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%timeit \n",
    "tf = get_tf(corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='files/resources/ic_assignment_black_24dp_2x.png' align='left'>\n",
    "Use the function `get_tf()` to compute term frequency for the across the large corpus of item titles in the list `items_t`.      \n",
    "What is the frequency of the terms 'unicycle', 'bicycle' and 'tricycle'?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise Set 2 - Document Term Frequency\n",
    "\n",
    "So far we have computed the term frequency across the entire corpus.  The term frequency could also be computed for each document.  For short documents, such as eBay item titles, terms do not occur very frequently.  In longer documents the term frequency is a form of compression and summarization.\n",
    "\n",
    "We can store the document term frequency in a dictionary, where the key is the document id and the value is the a nested dictionary of document terms and their counts.\n",
    "\n",
    "For example consider the corpus of three documents:\n",
    "\n",
    "1. 'mountain bike red with red saddle'\n",
    "2. 'road bike carbon'\n",
    "3. 'bike helmet'\n",
    "\n",
    "The document term frequencies would be:\n",
    "\n",
    "| id | document term frequencies |\n",
    "|----|------------------|\n",
    "| 1  | { 'mountain' : 1, 'bike' : 1, 'red' : 2, 'with' : 1 } |\n",
    "| 2  | { 'road' : 1, 'bike' : 1, 'carbon' : 1 } |\n",
    "| 3  | { 'bike' : 1, 'helmet' : 1 } |\n",
    "\n",
    "\n",
    "<img src='files/resources/ic_assignment_black_24dp_2x.png' align='left'>\n",
    "Complete the function definintion `get_tf()` to compute the **document term frequencies** for a single document.  This function is then called once per document in the corpus by the function `get_df()`.   Print out the document term frequencies for 3 randomly selected documents - what was the highest frequency term for each?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import collections\n",
    "\n",
    "def get_tf(document):\n",
    "    tf = Counter()\n",
    "    # << COMPUTE TERM FREQUENCY FOR DOCUMENT >> \n",
    "    # FOR EACH word IN document \n",
    "    #   IF word IN tf THEN tf[word] = tf[word] + 1\n",
    "    # CODE HERE >>\n",
    "    \n",
    "    return tf\n",
    "\n",
    "def get_dtf(corpus):\n",
    "    dtf = {}\n",
    "    for i,doc in enumerate(corpus):\n",
    "        dtf[i]=get_tf(doc)\n",
    "    return dtf\n",
    "            \n",
    "    \n",
    "dtf = get_dtf(items_t)\n",
    "dtf[4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='files/resources/ic_assignment_black_24dp_2x.png' align='left'>\n",
    "Now compute the document term frequencies for the full corpus of item descriptions in `items_d`.  \n",
    "Print out the document term frequency for 3 randomly selected documents - what was the highest frequency term for each? How does the term frequency for the titles compare to the descriptions?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# << COMPUTE DTF FOR ITEM DESCRIPTIONS >> CODE HERE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise Set 3 - Term Frequency Matrix\n",
    "\n",
    "Whilst the document term frequency dictionary in the previous section `tfd` is a compact way to store the term frequency it is not efficient for analysis.  A term frequency matrix is a more effective way to store the data if we wish to perform analysis - such as compare or rank documents. \n",
    "\n",
    "For example consider the corpus of three documents:\n",
    "\n",
    "1. 'mountain bike red'\n",
    "2. 'road bike carbon'\n",
    "3. 'bike helmet'\n",
    "\n",
    "There is a toal vocabulary of six terms [ 'mountain', 'bike' , 'red', 'road', 'carbon', 'helmet' ].\n",
    "\n",
    "Each document count be represented as a 3 x 6 element vectors:\n",
    "\n",
    "| Document ID | mountain | bike | red | road | carbon | helmet |\n",
    "|-------------|----------|------|-----|------|--------|--------|\n",
    "| 1 - 'mountain bike red' | 1 | 1 | 1 | 0 | 0 | 0 |\n",
    "| 2 - 'road bike carbon' | 0 | 1 | 0 | 1 | 1 | 0 |\n",
    "| 3 - 'bike helmet' | 0 | 1 | 0 | 0 | 0 | 1 |\n",
    "\n",
    "Those arrays can be stacked naturally into a matrix - one row per document, one column per term.  We call this matrix the term frequency matrix.\n",
    "\n",
    "To compute the term frequency matrix we have to first compute the lexicon (set of terms) in our corpus.\n",
    "\n",
    "<img src='files/resources/ic_assignment_black_24dp_2x.png' align='left'>\n",
    "Review the docs for the [set](https://docs.python.org/2/library/stdtypes.html#set-types-set-frozenset) type. Sets do not allow duplicates and can be used to compute unique terms in a document.  Run the code below and make sure you understand what is happening before continuing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "s = set()\n",
    "s.add('Hello')\n",
    "s.add('how')\n",
    "s.add('are')\n",
    "s.add('you')\n",
    "s.add('doing')\n",
    "s.add('Hello')\n",
    "s.add('again!')\n",
    "print s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='files/resources/ic_assignment_black_24dp_2x.png' align='left'>\n",
    "Complete the `get_lexicon()` function definition so that it returns a list of unique terms for a given corpus of documents.  Validate the results with the small test corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_lexicon(corpus):\n",
    "    lexicon = set()\n",
    "    # << COMPUTE SET OF TERMS IN CORPUS >>\n",
    "    # FOR EACH document IN corpus\n",
    "    #   FOR EACH word IN document\n",
    "    #     ADD word TO lexicon\n",
    "    # >> CODE HERE\n",
    "    \n",
    "    return list(lexicon)\n",
    "    \n",
    "test_corpus = ['mountain bike red','road bike carbon','bike helmet']\n",
    "lexicon = get_lexicon(test_corpus)\n",
    "print lexicon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have our lexicon we can compute a term frequency matrix - the term frequency matrix will have one row per document in our corpus and one column per term in our lexicon.   \n",
    "\n",
    "<img src='files/resources/ic_assignment_black_24dp_2x.png' align='left'>\n",
    "Complete the function definition below which computes the term frequency matrix for a corpus of documents.  You need to compute the term frequency vector `tfv` for each document in the corpus.  Validate the results with the small test corpus provided."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_tfm(corpus):\n",
    "    \n",
    "    def get_lexicon(corpus):\n",
    "        lexicon = set()\n",
    "        for doc in corpus:\n",
    "            lexicon.update([word for word in doc.split()])\n",
    "        return list(lexicon)\n",
    "        \n",
    "    lexicon = get_lexicon(corpus)\n",
    "\n",
    "    tfm =[]\n",
    "    for doc in corpus:\n",
    "        tfv = [0]*len(lexicon)\n",
    "        for term in doc.split():\n",
    "            # << COMPUTE DOCUMENT TERM FREQUENCY VECTOR >>\n",
    "            # i = INDEX OF term IN lexicon\n",
    "            # tfv[i] = tfv[i] +1\n",
    "            # CODE HERE >>\n",
    "            \n",
    "        tfm.append(tfv)\n",
    "        \n",
    "    return tfm, lexicon\n",
    "\n",
    "\n",
    "test_corpus = ['mountain bike red','road bike carbon','bike helmet']\n",
    "tfm, lexicon = get_tfm(test_corpus)\n",
    "print(lexicon)\n",
    "print(tfm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sparsity of term frequency matrix\n",
    "\n",
    "<img src='files/resources/ic_info_outline_black_24dp_2x.png' align='left'> \n",
    "As our corpus increases so does the sparsity of the term frequency matrix - most elements have value zero.  \n",
    "We can use more efficient [sparse matrix](https://en.wikipedia.org/wiki/Sparse_matrix) storage to save memory.  More details [here](http://localhost:8888/notebooks/1.3%20Introduction%20to%20Information%20Retrieval.ipynb#Sparse-Term-Frequency-Matrix).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from bokeh.plotting import figure, output_notebook, show, vplot\n",
    "\n",
    "# Sparsity as a function of document count\n",
    "n = []\n",
    "s = []\n",
    "for i in range(100,1000,100):\n",
    "    corpus = items_t[0:i]\n",
    "    tfm, lexicon = get_tfm(corpus)\n",
    "    c =[ [x.count(0), x.count(1)] for x in tfm]\n",
    "    n_zero = sum([ y[0] for y in c])\n",
    "    n_one = sum([ y[1] for y in c])  \n",
    "    s.append(1.0 - (float(n_one) / (n_one + n_zero)))\n",
    "    n.append(i)\n",
    "    \n",
    "output_notebook(hide_banner=True)\n",
    "p = figure(x_axis_label='Documents', y_axis_label='Sparsity',\n",
    "          plot_width=400, plot_height=400)\n",
    "p.line(n, s, line_width=2)\n",
    "p.circle(n, s, fill_color=\"white\", size=8)\n",
    "show(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise Set 4 - Boolean Search\n",
    "\n",
    "We are now in a position to write our first ranking function.  Now we have the term frequency matrix we can use it to find documents that contain words included in a user specified query.  We will start by simply returning the documents from the corpus that match any terms in the query and rank by the raw frequency of matching terms. \n",
    "\n",
    "More specifically our algorithm for 'boolean search' proceeds as follows:\n",
    "\n",
    "* Compute the lexicon for the corpus\n",
    "* Compute the term frequency matrix for the corpus\n",
    "* Convert query to query vector using the same lexicon \n",
    "* Compare each documents term frequncy vector to the query vector - specifically for each document in the corpus:\n",
    "    * Compute a ranking score for each document by taking the [dot product](https://en.wikipedia.org/wiki/Dot_product) of the document's term frequency vector and the query vector\n",
    "* Sort the documents by ranking score\n",
    "\n",
    "\n",
    "What is a dot product?  The dot product is a way of measuring the sum of the frequency of terms in the document that that occur in the query.  At a high level documents that match well will score more highly than documents that do not match.  Here is a [gist](https://gist.github.com/mattwg/60910d90a8987e271212) that shows how to compute the dot product between two vectors.\n",
    "\n",
    "<img src='files/resources/ic_assignment_black_24dp_2x.png' align='left'>  Make sure you understand the code below before continuing.  Which document matches the query most closely?  \n",
    "What document matches the query 'red racing bike' best?  Why did the extra token in the query not affect the results?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_corpus = ['mountain bike red','road bike carbon','bike helmet']\n",
    "print(test_corpus)\n",
    "\n",
    "# Compute term frequency matrix and lexicon\n",
    "tfm, lexicon = get_tfm(test_corpus)\n",
    "\n",
    "print(tfm)\n",
    "print(lexicon)\n",
    "\n",
    "# Define our query\n",
    "qry = 'red bike'\n",
    "\n",
    "# Convert query to query vector using lexicon\n",
    "qrv = [0]*len(lexicon)\n",
    "for term in qry.split():\n",
    "    if term in lexicon:\n",
    "        qrv[lexicon.index(term)] = 1\n",
    "            \n",
    "print(qrv)\n",
    "\n",
    "# Compare query vector to each term frequency vector\n",
    "# This is dot product between qrv and each row of tfm\n",
    "for i,tfv in enumerate(tfm):\n",
    "    print i , sum([ xy[0] * xy[1] for xy in zip(qrv,tfv)])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "<img src='files/resources/ic_assignment_black_24dp_2x.png' align='left'>\n",
    "The function definition `get_results_tf()` computes the document ranking score for each document in the term frequency matrix.  The function returns a list of document id's sorted by their score.  Complete the function by providing the code to compute the score of each document.  Test using a bike related query such as 'led bike light'.  Do you get relevant results?  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_results_tf(qry, tfm, lexicon):\n",
    "    qrv = [0]*len(lexicon)\n",
    "    for term in qry.split():\n",
    "        if term in lexicon:\n",
    "            qrv[lexicon.index(term)] = 1\n",
    "\n",
    "    results = []      \n",
    "    for i, tfv in enumerate(tfm):\n",
    "        score = 0\n",
    "        # << COMPUTE DOCUMENT SCORE >>\n",
    "        # score = DOT PRODUCT ( qrv, tfv ) \n",
    "        # >> CODE HERE\n",
    "        \n",
    "        results.append([score, i])\n",
    "    \n",
    "    sorted_results = sorted(results, key=lambda t: t[0] * -1 )\n",
    "    return sorted_results\n",
    "\n",
    "\n",
    "def print_results(results,n, head=True):\n",
    "    ''' Helper function to print results\n",
    "    '''\n",
    "    if head:    \n",
    "        print('\\nTop %d from recall set of %d items:' % (n,len(results)))\n",
    "        for r in results[:n]:\n",
    "            print('\\t%0.2f - %s'%(r[0],items_t[r[1]]))\n",
    "    else:\n",
    "        print('\\nBottom %d from recall set of %d items:' % (n,len(results)))\n",
    "        for r in results[-n:]:\n",
    "            print('\\t%0.2f - %s'%(r[0],items_t[r[1]]))\n",
    "    \n",
    "\n",
    "tfm, lexicon = get_tfm(items_t)\n",
    "results = get_results_tf('led bike light', tfm , lexicon)\n",
    "print_results(results,10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise Set 5 - Inverted Index\n",
    "\n",
    "The previous example gets computationally expensive as the corpus grows - due to the increasing sparsity of the term frequency matrix the dot product for many documents is zero!  To solve this problem we can create an inverted index.  An inverted index can be used to filter out documents that do not contain any of the keywords in the query before computing the ranking score.  We know that these documents would score zero in the ranking scheme we are implementing.\n",
    "\n",
    "Using our example mini-corpus:\n",
    "\n",
    "1. 'mountain bike red'\n",
    "2. 'road bike carbon'\n",
    "3. 'bike helmet'\n",
    "\n",
    "There is a toal vocabulary of six terms [ 'mountain', 'bike' , 'red', 'road', 'carbon', 'helmet' ].  An inverted index will map each of these terms to the document in which the document can be found.  \n",
    "\n",
    "| key | value |\n",
    "|-----|-------|\n",
    "| 'mountain' | [ 1 ] |  \n",
    "| 'bike' | [1, 2, 3] |  \n",
    "| 'red' | [1] |  \n",
    "| 'road' |  [2] | \n",
    "| 'carbon' | [2] | \n",
    "|  'helmet' | [3] |\n",
    "\n",
    "Today we will store our inverted index in a dictionary where the key is the term and the value is the list of matching document id's.\n",
    "\n",
    "<img src='files/resources/ic_assignment_black_24dp_2x.png' align='left'>\n",
    "We will create an inverted index as a python dictionary keyed on the token.  \n",
    "Complete the code snippet below to create the inverted index.  Validate with the test corpus. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def create_inverted_index(corpus):\n",
    "    idx={}\n",
    "    for i, document in enumerate(corpus):\n",
    "        # << POPULATE INVERTED INDEX >>\n",
    "        # FOR EACH word IN document\n",
    "        #   IF word IN KEYS(idx) THEN ADD document_id TO VALUE(idx[word])\n",
    "        #   ELSE idx[word] = NEW LIST (document_id)\n",
    "        # CODE HERE >>\n",
    "        \n",
    "    return idx\n",
    "\n",
    "test_corpus = ['mountain bike red','road bike carbon','bike helmet']\n",
    "idx = create_inverted_index(test_corpus)\n",
    "print(idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='files/resources/ic_assignment_black_24dp_2x.png' align='left'>\n",
    "Now we can create an inverted index for all the item titles.  We can use the set intersection method to find all the documents that match the query 'led bike light'.  Run the code below checking the titles of some of the results that match query terms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "idx = create_inverted_index(items_t)\n",
    "print(set(idx['led']).intersection(set(idx['bike'])).intersection(set(idx['light'])))\n",
    "print(items_t[2061])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now improve on our first ranking function.  This time only scoring the documents that match our keywords in the query:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_results_tf(qry, idx):\n",
    "    score = Counter()\n",
    "    for term in qry.split():\n",
    "        for doc in idx[term]:\n",
    "            score[doc] += 1\n",
    "            \n",
    "    results=[]\n",
    "    for x in [[r[0],r[1]] for r in zip(score.keys(), score.values())]:\n",
    "        if x[1] > 0:\n",
    "            # output [0] score, [1] doc_id\n",
    "            results.append([x[1],x[0]])\n",
    "\n",
    "    sorted_results = sorted(results, key=lambda t: t[0] * -1 )\n",
    "    return sorted_results;\n",
    "\n",
    "\n",
    "idx = create_inverted_index(items_t)\n",
    "results = get_results_tf('led bike light', idx)\n",
    "print_results(results,20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='files/resources/ic_assignment_black_24dp_2x.png' align='left'>\n",
    "Run a few different queries some longer some shorter - for example 'front rear led light', 'led light', 'led'.  What do you notice about the ranking score?\n",
    "Try the query 'mountain bike suspension' - do the results look relevant?  What might be going on?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# << ENTER DIFFERENT QUERIES >> \n",
    "results = get_results_tf('mountain bike suspension', idx)\n",
    "print_results(results, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='files/resources/ic_info_outline_black_24dp_2x.png' align='left'> \n",
    "The term frequency ranking is dominated by high frequency terms.  For example the term bike is present in nearly every other document.  Bike is over represented compared to more meaningful terms 'mountain' and 'suspension'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from bokeh.plotting import output_notebook, show\n",
    "from bokeh.charts import Bar\n",
    "from bokeh.charts.attributes import CatAttr\n",
    "\n",
    "df = pd.DataFrame({'term':[x for x in idx.keys()],'freq':[len(x) for x in idx.values()]})\n",
    "\n",
    "output_notebook(hide_banner=True)\n",
    "p = Bar(df.sort_values('freq', ascending=False)[:30], label=CatAttr(columns=['term'], sort=False), values='freq',\n",
    "        plot_width=800, plot_height=400)\n",
    "show(p)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise Set 6 - TF-IDF\n",
    "\n",
    "We already have all the information we need to compute IDF.  Reminder the Inverse Document Frequency is a weight we apply to each term in our lexicon.  The 'smooth' IDF for a specific term is computed as follows:\n",
    "\n",
    "$$\n",
    "IDF = log ( 1 + \\frac{N}{n_t} ) \n",
    "$$\n",
    "\n",
    "Where $N$ is the number of documents in the corpus and $n_t$ is the number of documents in the corpus in which the term $t$ appears.  $n_t$ is simply the length of the list of documents for a given key in our inverted index.\n",
    "\n",
    "<img src='files/resources/ic_assignment_black_24dp_2x.png' align='left'>\n",
    "Complete the function definition to compute IDF for a given term, given an inverted index `idx` and number of documents `n`. The log function is in the [math](https://docs.python.org/2/library/math.html) module.  Compute the IDF of the terms 'mountain', 'bike' and 'suspension'. Which term has the highest IDF?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def idf(term, idx, n):\n",
    "    # << IMPLEMENT IDF FUNCTION >> CODE HERE\n",
    "    # CODE HERE >>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF Intuition\n",
    "\n",
    "<img src='files/resources/ic_info_outline_black_24dp_2x.png' align='left'>We can plot the relationship between TF and IDF and get more intuition for what TF and IDF is all about.  Plotting data to understand algorithms is good practice - not only to develop intuition but also to spot bugs in your code!  We will revisit this later in the day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from bokeh.charts import vplot\n",
    "\n",
    "idx = create_inverted_index(items_t)\n",
    "\n",
    "df = pd.DataFrame({'term':[x for x in idx.keys()],'freq':[len(x) for x in idx.values()],\n",
    "                  'idf':[idf(x, idx, len(items_t)) for x in idx.keys()]})\n",
    "\n",
    "output_notebook(hide_banner=True)\n",
    "p1 = Bar(df.sort_values('freq', ascending=False)[:30], label=CatAttr(columns=['term'], sort=False), values='freq',\n",
    "        plot_width=800, plot_height=400)\n",
    "p2 = Bar(df.sort_values('freq', ascending=False)[:30], label=CatAttr(columns=['term'], sort=False), values='idf',\n",
    "        plot_width=800, plot_height=400)\n",
    "p = vplot(p1, p2)\n",
    "show(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TD-IDF Ranking \n",
    "\n",
    "To rank based on TF-IDF we only need to make a few small changes to the previous boolean ranking function `get_results_tf()`:\n",
    "\n",
    "1. We need to know how many times the term `t` appears in `D`.  We can store this in our inverted index.  Instead of storing the document ID we can add the document ID and the number of times the term appears.  Previously this was captured in the TF matrix. We can avoid computing the TF matrix if adjust our index.\n",
    "2. We have to change the function signature in the ranking function - passing in the total size of the corpus.\n",
    "3. We also have to change the score calculation to incorporate the IDF weighting.\n",
    "\n",
    "<img src='files/resources/ic_assignment_black_24dp_2x.png' align='left'>\n",
    "Complete the `get_results_tfidf()` function to score documents based on TF-IDF.  Run a few different queries some longer some shorter - for example 'front rear led light', 'led light', 'led'.  What do you notice about the ranking score?  How do they compare to the TF ranking?  Try the query 'mountain bike suspension' - do the results look more or less relevant than TF?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def create_inverted_index(corpus):\n",
    "    idx={}\n",
    "    for i, doc in enumerate(corpus):\n",
    "        for word in doc.split():\n",
    "            if word in idx:\n",
    "                if i in idx[word]:\n",
    "                    # Update document's frequency\n",
    "                    idx[word][i] += 1\n",
    "                else:\n",
    "                    # Add document\n",
    "                    idx[word][i] = 1\n",
    "            else:\n",
    "                # Add term\n",
    "                idx[word] = {i:1}\n",
    "    return idx\n",
    "\n",
    "def get_results_tfidf(qry, idx, n):\n",
    "    score = Counter()\n",
    "    for term in qry.split():\n",
    "        # << IMPLEMENT TF-IDF SCORING >> \n",
    "        # CODE HERE >>\n",
    "        \n",
    "        \n",
    "    results=[]\n",
    "    for x in [[r[0],r[1]] for r in zip(score.keys(), score.values())]:\n",
    "        if x[1] > 0:\n",
    "            results.append([x[1],x[0]])\n",
    "    \n",
    "    sorted_results = sorted(results, key=lambda t: t[0] * -1 )\n",
    "    return sorted_results\n",
    "\n",
    "idx = create_inverted_index(items_t)\n",
    "# results = get_results_tfidf('front led bike light', idx, len(items_t))\n",
    "# results = get_results_tfidf('led bike light', idx, len(items_t))\n",
    "# results = get_results_tfidf('led', idx, len(items_t))\n",
    "results = get_results_tfidf('mountain bike suspension', idx, len(items_t))\n",
    "print_results(results,10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problematic Queries\n",
    "\n",
    "Although we have 'fixed' the suspension query we now see another problem with the query \"mountain bikes\" which seems to just return a heap of accessories:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "idx = create_inverted_index(items_t)\n",
    "results = get_results_tfidf('mountain bike', idx, len(items_t))\n",
    "print_results(results,10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The items scoring highly have more terms in them.  The more terms in a title the more likely it is to match.  It is also possible to have duplicate terms - such as the double occurence of 'mountain'.\n",
    "\n",
    "This would lead us to hypothesize that we should penalise items where there are many more terms in the item title.  We might assume that results that score highly but have fewer terms are better that results that score highly but contain many terms.   \n",
    "\n",
    "In addition TF-IDF seems to result in many items getting exactly the same score - we would prefer to be able to seperate out the results rather than have 8 scoring 4.06.  It turns out that there are only 6 different TF-IDF scores that the query 'mountain bike' generates with this corpus:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'score':[float(x[0]) for x in results],\n",
    "                   'title':[items_t[x[1]] for x in results]})\n",
    "\n",
    "d = df.groupby('score').first().reset_index()\n",
    "\n",
    "r1 = re.compile('(bike)')\n",
    "r2 = re.compile('(mountain)')\n",
    "\n",
    "for i, t in enumerate(d.title):\n",
    "    n1 = r1.findall(t)\n",
    "    n2 = r2.findall(t)\n",
    "    print('%d x Bike, %d x Mountain, Score = %0.2f'%(len(n1),len(n2),d.score[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from bokeh.plotting import output_notebook, show\n",
    "from bokeh.charts import Scatter\n",
    "\n",
    "# Plot score vs item length\n",
    "df = pd.DataFrame({'score':[float(x[0]) for x in results],\n",
    "                   'length':[len(items_t[x[1]].split()) for x in results]})\n",
    "\n",
    "output_notebook(hide_banner=True)\n",
    "p = Scatter(df, x='score', y='length')\n",
    "show(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ideally we do not want scores to be the same for lots of documents. High TF-IDF scores in shorter documents should be more relevant - so we could try by boosting the score for documents that are shorter than average."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_results_tfidf_boost(qry, corpus):\n",
    "    idx = create_inverted_index(corpus)\n",
    "    n = len(corpus)\n",
    "    d = [len(x.split()) for x in corpus]\n",
    "    d_avg = float(sum(d)) / len(d)\n",
    "    score = Counter()\n",
    "    for term in qry.split():\n",
    "        if term in idx:\n",
    "            i = idf(term, idx, n)\n",
    "            for doc in idx[term]:\n",
    "                f = float(idx[term][doc])\n",
    "                score[doc] += i *  ( f / (float(d[doc]) / d_avg) )\n",
    "        \n",
    "    results=[]\n",
    "    for x in [[r[0],r[1]] for r in zip(score.keys(), score.values())]:\n",
    "        if x[1] > 0:\n",
    "            # output [0] score, [1] doc_id\n",
    "            results.append([x[1],x[0]])\n",
    "\n",
    "    sorted_results = sorted(results, key=lambda t: t[0] * -1 )\n",
    "    return sorted_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "results = get_results_tfidf_boost('mountain bike', items_t)\n",
    "print_results(results, 10)\n",
    "\n",
    "# Plot score vs item length\n",
    "df = pd.DataFrame({'score':[float(x[0]) for x in results],\n",
    "                   'length':[len(items_t[x[1]].split()) for x in results]})\n",
    "\n",
    "output_notebook()\n",
    "p = Scatter(df, x='score', y='length')\n",
    "show(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That looks better!  This intuition will be built upon in the next section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise Set 7 - Implementing BM25\n",
    "\n",
    "<img src='files/resources/ic_assignment_black_24dp_2x.png' align='left'> In this exercise the goal is to implement the BM25 algorithm.   \n",
    "To help you I have provided comments breaking this down into steps 1 through 5.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_results_bm25(qry, corpus, k1=1.5, b=0.75):\n",
    "    idx = create_inverted_index(corpus)\n",
    "    # 1.Assign (integer) n to be the number of documents in the corpus\n",
    "    # CODE HERE >>\n",
    "    \n",
    "    # 2.Assign (list) d with elements corresponding to the number of terms in each document in the corpus\n",
    "    # CODE HERE >>\n",
    "    \n",
    "    # 3.Assign (float) d_avg as the average document length of the documents in the corpus\n",
    "    # CODE HERE >>\n",
    "    \n",
    "    score = Counter()\n",
    "    for term in qry.split():\n",
    "        if term in idx:\n",
    "            i = idf(term, idx, n)\n",
    "            for doc in idx[term]:\n",
    "                # 4.Assign (float) f equal to the number of times the term appears in doc\n",
    "                # CODE HERE >>\n",
    "                \n",
    "                # 5.Assign (float) s the BM25 score for this (term, document) pair\n",
    "                # CODE HERE >>\n",
    "                \n",
    "                score[doc] += s\n",
    "                \n",
    "    results=[]\n",
    "    for x in [[r[0],r[1]] for r in zip(score.keys(), score.values())]:\n",
    "        if x[1] > 0:\n",
    "            results.append([x[1],x[0]])\n",
    "\n",
    "    sorted_results = sorted(results, key=lambda t: t[0] * -1 )\n",
    "    return sorted_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "results = get_results_bm25('mountain bike', items_t)\n",
    "print_results(results, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='files/resources/ic_assignment_black_24dp_2x.png' align='left'> Test BM25 with different parameter values.  \n",
    "Can you observe the effect of varying k1 and b?  What happens if k1=0?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "results = get_results_bm25('mountain bike', items_t, k1=1.5, b=0.75)\n",
    "\n",
    "# Plot score vs item length\n",
    "df = pd.DataFrame({'score':[float(x[0]) for x in results],\n",
    "                   'length':[len(items_t[x[1]].split()) for x in results]})\n",
    "output_notebook()\n",
    "p = Scatter(df, x='score', y='length')\n",
    "show(p)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
