{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On Day 1 we were using a lot of core python functions to process and tokenize the text data.  This is overly complex and time consuming for real data.  \n",
    "\n",
    "We would prefer to reuse other work in this area - NLTK is one library that is designed to simplify working with text.  NLTK has been called “a wonderful tool for teaching, and working in, computational linguistics using Python,” and “an amazing library to play with natural language.”\n",
    "\n",
    "The Python 2 Guide is available [here](http://nltk.org/book_1ed):\n",
    "\n",
    "Bird, Steven, Edward Loper and Ewan Klein (2009), _Natural Language Processing with Python._ O’Reilly Media Inc.\n",
    "\n",
    "Before we can get going we need to download the nltk resources:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "#nltk.download()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can load our bike items from day 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Cycling Bicycle MTB Bike Fixie Gloss 3K Carbon Fiber Riser Bar Handlebar 31.8mm', 'BICYCLE RIMS 26\"x 50MM RED 3 SPEED INTERNAL HUB WHEEL SET BEACH CRUISER BIKE', 'Mavic Crossride 26\" Mountain bike wheels and WTB Weirwolf Tires', 'New KCNC ARROW 7050 Alloy Stem , 31.8x150mm , 149g , Black', 'ROTOR QXL Aero Oval Road Chainring BCD110x5 53t']\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "r = csv.reader(open('data/bike-items.txt'),delimiter=',', quotechar='\"')\n",
    "items = [ line[0] for i, line in enumerate(r) if i > 1]\n",
    "print(items[0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Cycling', 'Bicycle', 'MTB', 'Bike', 'Fixie', 'Gloss', '3K', 'Carbon', 'Fiber', 'Riser', 'Bar', 'Handlebar', '31.8mm'], ['BICYCLE', 'RIMS', '26', \"''\", 'x', '50MM', 'RED', '3', 'SPEED', 'INTERNAL', 'HUB', 'WHEEL', 'SET', 'BEACH', 'CRUISER', 'BIKE'], ['Mavic', 'Crossride', '26', \"''\", 'Mountain', 'bike', 'wheels', 'and', 'WTB', 'Weirwolf', 'Tires'], ['New', 'KCNC', 'ARROW', '7050', 'Alloy', 'Stem', ',', '31.8x150mm', ',', '149g', ',', 'Black'], ['ROTOR', 'QXL', 'Aero', 'Oval', 'Road', 'Chainring', 'BCD110x5', '53t']]\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "items_t = [ word_tokenize(item) for item in items]\n",
    "print(items_t[0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stopword Removal\n",
    "\n",
    "Some words just aren't important, word such as:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{u'a',\n",
       " u'about',\n",
       " u'above',\n",
       " u'after',\n",
       " u'again',\n",
       " u'against',\n",
       " u'ain',\n",
       " u'all',\n",
       " u'am',\n",
       " u'an',\n",
       " u'and',\n",
       " u'any',\n",
       " u'are',\n",
       " u'aren',\n",
       " u'as',\n",
       " u'at',\n",
       " u'be',\n",
       " u'because',\n",
       " u'been',\n",
       " u'before',\n",
       " u'being',\n",
       " u'below',\n",
       " u'between',\n",
       " u'both',\n",
       " u'but',\n",
       " u'by',\n",
       " u'can',\n",
       " u'couldn',\n",
       " u'd',\n",
       " u'did',\n",
       " u'didn',\n",
       " u'do',\n",
       " u'does',\n",
       " u'doesn',\n",
       " u'doing',\n",
       " u'don',\n",
       " u'down',\n",
       " u'during',\n",
       " u'each',\n",
       " u'few',\n",
       " u'for',\n",
       " u'from',\n",
       " u'further',\n",
       " u'had',\n",
       " u'hadn',\n",
       " u'has',\n",
       " u'hasn',\n",
       " u'have',\n",
       " u'haven',\n",
       " u'having',\n",
       " u'he',\n",
       " u'her',\n",
       " u'here',\n",
       " u'hers',\n",
       " u'herself',\n",
       " u'him',\n",
       " u'himself',\n",
       " u'his',\n",
       " u'how',\n",
       " u'i',\n",
       " u'if',\n",
       " u'in',\n",
       " u'into',\n",
       " u'is',\n",
       " u'isn',\n",
       " u'it',\n",
       " u'its',\n",
       " u'itself',\n",
       " u'just',\n",
       " u'll',\n",
       " u'm',\n",
       " u'ma',\n",
       " u'me',\n",
       " u'mightn',\n",
       " u'more',\n",
       " u'most',\n",
       " u'mustn',\n",
       " u'my',\n",
       " u'myself',\n",
       " u'needn',\n",
       " u'no',\n",
       " u'nor',\n",
       " u'not',\n",
       " u'now',\n",
       " u'o',\n",
       " u'of',\n",
       " u'off',\n",
       " u'on',\n",
       " u'once',\n",
       " u'only',\n",
       " u'or',\n",
       " u'other',\n",
       " u'our',\n",
       " u'ours',\n",
       " u'ourselves',\n",
       " u'out',\n",
       " u'over',\n",
       " u'own',\n",
       " u're',\n",
       " u's',\n",
       " u'same',\n",
       " u'shan',\n",
       " u'she',\n",
       " u'should',\n",
       " u'shouldn',\n",
       " u'so',\n",
       " u'some',\n",
       " u'such',\n",
       " u't',\n",
       " u'than',\n",
       " u'that',\n",
       " u'the',\n",
       " u'their',\n",
       " u'theirs',\n",
       " u'them',\n",
       " u'themselves',\n",
       " u'then',\n",
       " u'there',\n",
       " u'these',\n",
       " u'they',\n",
       " u'this',\n",
       " u'those',\n",
       " u'through',\n",
       " u'to',\n",
       " u'too',\n",
       " u'under',\n",
       " u'until',\n",
       " u'up',\n",
       " u've',\n",
       " u'very',\n",
       " u'was',\n",
       " u'wasn',\n",
       " u'we',\n",
       " u'were',\n",
       " u'weren',\n",
       " u'what',\n",
       " u'when',\n",
       " u'where',\n",
       " u'which',\n",
       " u'while',\n",
       " u'who',\n",
       " u'whom',\n",
       " u'why',\n",
       " u'will',\n",
       " u'with',\n",
       " u'won',\n",
       " u'wouldn',\n",
       " u'y',\n",
       " u'you',\n",
       " u'your',\n",
       " u'yours',\n",
       " u'yourself',\n",
       " u'yourselves'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "s = set(stopwords.words('english'))\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Mavic', 'Crossride', '26', \"''\", 'Mountain', 'bike', 'wheels', 'and', 'WTB', 'Weirwolf', 'Tires']\n",
      "set(['and', 'Mountain', '26', 'Mavic', 'Crossride', \"''\", 'Tires', 'WTB', 'bike', 'Weirwolf', 'wheels'])\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "t = 'Mavic Crossride 26\" Mountain bike wheels and WTB Weirwolf Tires'\n",
    "tt = word_tokenize(t)\n",
    "print(tt)\n",
    "ttt = set(tt)\n",
    "print(ttt)\n",
    "tttt = ttt.difference_update(s)\n",
    "print(tttt)\n",
    "\n",
    "\n",
    "#items_t2 = [ set(words).difference_update(stopwords) for words in items_t]\n",
    "#items_t2[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stemming\n",
    "\n",
    "Can be useful but in the context of item titles is this appropriate?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Synonyms \n",
    "\n",
    "Query expansion using synonyms especially when result set contains few or no items."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spelling\n",
    "\n",
    "We could correct spelling mistakes on the item titles but also we should ensure that query has no spelling mistakes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
