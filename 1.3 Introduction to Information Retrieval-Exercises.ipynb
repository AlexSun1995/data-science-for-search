{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Introduction to Information Retrieval\n",
    "\n",
    "Here we work with a data set scraped from eBay.  The data contains 9895 item titles and descriptions.\n",
    "\n",
    "First we load the data file and _normalise_ the text - removing certain characters and converting to lower case.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import math\n",
    "\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "from bokeh.plotting import figure, output_notebook, show, vplot\n",
    "from bokeh.charts import Bar, Scatter, BoxPlot\n",
    "from bokeh.charts.attributes import CatAttr\n",
    "from bokeh.models import ColumnDataSource\n",
    "\n",
    "from sys import getsizeof"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import re\n",
    "\n",
    "with open(\"data/bike-items.txt\") as f:\n",
    "    r = csv.reader(f, delimiter=',', quotechar='\"')\n",
    "    rgx = re.compile(r'\\b[a-zA-Z]+\\b') \n",
    "    docs = [ (' '.join(re.findall(rgx, x[0])).lower(), ' '.join(re.findall(rgx, x[1])).lower())  \\\n",
    "                for i,x in enumerate(r) if i > 1 ]\n",
    "    \n",
    "print(docs[0][0],docs[0][1])\n",
    "\n",
    "items_t = [ d[0] for d in docs ] # item titles\n",
    "items_d = [ d[1] for d in docs ] # item descriptions\n",
    "items_i = range(0, len(items_t)) # item id\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise Set 1 - Term Frequency\n",
    "\n",
    "Let's start with the first 10 item titles as out corpus:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "corpus = items_t[0:5]\n",
    "print(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ic_assignment_black_24dp_2x.png  ic_info_outline_black_24dp_2x.png\r\n",
      "ic_build_black_24dp_2x.png\r\n"
     ]
    }
   ],
   "source": [
    "!ls resources/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our goal is to enumerate over the corpus of documents, tokenize the documents and count the frequency of tokens. \n",
    "\n",
    "<img src='files/resources/ic_assignment_black_24dp_2x.png' align='left'>\n",
    "Here is a part completed code snippet to compute term frequency.  \n",
    "Complete this code to correctly populate the dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tf = {}\n",
    "for doc in corpus:\n",
    "    for word in doc.split():\n",
    "        # << CODE HERE\n",
    "        \n",
    "print(tf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can simplify by using a [Counter](https://docs.python.org/2/library/collections.html#collections.Counter) rather than a dictionary.\n",
    "\n",
    "<img src='files/resources/ic_assignment_black_24dp_2x.png' align='left'> \n",
    "Take a look at the docs for the `Counter` collection.  \n",
    "Complete this code snippet to compute term frequency using the `Counter`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "tf = Counter()\n",
    "for doc in corpus:\n",
    "    for word in doc.split():\n",
    "        # << CODE HERE\n",
    "\n",
    "print(tf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Counter does not give us a real speed advantage - since it does more work.   For these tiny data sets we do not see any difference - however in Python 3 it is faster than a default dictionary.  Often times best way to test performance is to time code execution.\n",
    "\n",
    "<img src='files/resources/ic_info_outline_black_24dp_2x.png' align='left'> \n",
    "We should get used to thinking about performance.   \n",
    "We can use the Jupyter Notebook [magics](http://nbviewer.jupyter.org/github/ipython/ipython/blob/1.x/examples/notebooks/Cell%20Magics.ipynb) to time the execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The slowest run took 23.54 times longer than the fastest. This could mean that an intermediate result is being cached \n",
      "10000000 loops, best of 3: 91.2 ns per loop\n",
      "The slowest run took 16.05 times longer than the fastest. This could mean that an intermediate result is being cached \n",
      "1000000 loops, best of 3: 995 ns per loop\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def tf1(corpus):\n",
    "    tf = {}\n",
    "    # << DICTIONARY TERM FREQUENCY CODE HERE\n",
    "    return tf\n",
    "\n",
    "def tf2(corpus):\n",
    "    tf = Counter()\n",
    "    # << COUNTER TERM FREQUENCY CODE HERE\n",
    "    return tf\n",
    "\n",
    "%timeit tf1(corpus)\n",
    "%timeit tf2(corpus)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='files/resources/ic_assignment_black_24dp_2x.png' align='left'>\n",
    "Now compute term frequency for the full corpus of item titles.  \n",
    "What is the frequency of the terms 'Unicycle', 'Bicycle' and 'Tricycle'?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF Matrix\n",
    "\n",
    "Whilst the TF dictionary is a compact way to store the term frequency it is not much use for analysis.  We need a TF matrix where each document vector is the same length.  Now we convert the dictionary to a matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_lexicon(corpus):\n",
    "    lexicon = set()\n",
    "    for doc in corpus:\n",
    "        lexicon.update([word for word in doc.split()])\n",
    "    return lexicon\n",
    "\n",
    "lexicon = get_lexicon(corpus)\n",
    "\n",
    "tfm =[]\n",
    "for doc in corpus:\n",
    "    for term in doc.split():\n",
    "        tfv = [doc.split().count(word) for word in lexicon]\n",
    "    tfm.append(tfv)\n",
    "        \n",
    "print([ x for x in tfm])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As number of terms increases this method becomes inefficient.  Here is a faster implementation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_lexicon(corpus):\n",
    "    lexicon = set()\n",
    "    for doc in corpus:\n",
    "        lexicon.update([word for word in doc.split()])\n",
    "    return list(lexicon)\n",
    "\n",
    "lexicon = get_lexicon(corpus)\n",
    "\n",
    "tfm =[]\n",
    "for doc in corpus:\n",
    "    tfv = [0]*len(lexicon)\n",
    "    for term in doc.split():\n",
    "        tfv[lexicon.index(term)] += 1\n",
    "    tfm.append(tfv)\n",
    "        \n",
    "print(tfm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can compare time for each:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def tfm1(corpus):\n",
    "    \n",
    "    def get_lexicon(corpus):\n",
    "        lexicon = set()\n",
    "        for doc in corpus:\n",
    "            lexicon.update([word for word in doc.split()])\n",
    "        return lexicon\n",
    "    \n",
    "    lexicon = get_lexicon(corpus)\n",
    "\n",
    "    tfm =[]\n",
    "    for doc in corpus:\n",
    "        for term in doc.split():\n",
    "            tfv = [doc.split().count(word) for word in lexicon]\n",
    "        tfm.append(tfv)\n",
    "    \n",
    "    return tfm, lexicon\n",
    "\n",
    "def tfm2(corpus):\n",
    "    \n",
    "    def get_lexicon(corpus):\n",
    "        lexicon = set()\n",
    "        for doc in corpus:\n",
    "            lexicon.update([word for word in doc.split()])\n",
    "        return list(lexicon)\n",
    "\n",
    "    lexicon = get_lexicon(corpus)\n",
    "\n",
    "    tfm =[]\n",
    "    for doc in corpus:\n",
    "        tfv = [0]*len(lexicon)\n",
    "        for term in doc.split():\n",
    "            tfv[lexicon.index(term)] += 1\n",
    "        tfm.append(tfv)\n",
    "    \n",
    "    return (tfm, lexicon)\n",
    "\n",
    "%timeit tfm1(corpus)\n",
    "%timeit tfm2(corpus)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# as size of corpus increases so does the sparsity\n",
    "\n",
    "n = []\n",
    "s = []\n",
    "for i in range(100,1000,100):\n",
    "    corpus = items_t[0:i]\n",
    "    tfm, lexicon = tfm2(corpus)\n",
    "    c =[ [x.count(0), x.count(1)] for x in tfm]\n",
    "    n_zero = sum([ y[0] for y in c])\n",
    "    n_one = sum([ y[1] for y in c])  \n",
    "    s.append(1.0 - (float(n_one) / (n_one + n_zero)))\n",
    "    n.append(i)\n",
    "    \n",
    "output_notebook(hide_banner=True)\n",
    "p = figure(x_axis_label='Documents', y_axis_label='Sparsity',\n",
    "          plot_width=400, plot_height=400)\n",
    "p.line(n, s, line_width=2)\n",
    "p.circle(n, s, fill_color=\"white\", size=8)\n",
    "show(p)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can take advantage of the sparsity and only store the non-zero elements of the TF matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spare matrix storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def tfm3(corpus):\n",
    "    \n",
    "    def get_lexicon(corpus):\n",
    "        lexicon = set()\n",
    "        for doc in corpus:\n",
    "            lexicon.update([word for word in doc.split()])\n",
    "        return list(lexicon)\n",
    "\n",
    "    lexicon = get_lexicon(corpus)\n",
    "\n",
    "    tfm =[]\n",
    "    for doc_id, doc in enumerate(corpus):\n",
    "        tfv = [0]*len(lexicon)\n",
    "        for term in doc.split():\n",
    "            tfv[lexicon.index(term)] += 1\n",
    "        tfm.append([[(doc_id, t_id), t] for t_id, t in enumerate(tfv) if t > 0])\n",
    "    \n",
    "    return (tfm, lexicon)\n",
    "\n",
    "tfm, lexicon = tfm3(corpus)\n",
    "print(tfm[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also use compression to store this data even more efficiently - scikit-learn provides a compressed sparse matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tfm=csr_matrix(tfm2(corpus)[0])\n",
    "print(tfm[0,:])\n",
    "\n",
    "l = ['tf2','tfm2','csr']\n",
    "s = [getsizeof(tf2(corpus)[0]) , getsizeof(tfm2(corpus)[0]), getsizeof(csr_matrix(tfm2(corpus)[0]))]\n",
    "\n",
    "df = pd.DataFrame({'Type':l, 'Size':s})\n",
    "\n",
    "output_notebook(hide_banner=True)\n",
    "p = Bar(df.sort_values(by='Size'), label='Type', values='Size',\n",
    "        plot_width=400, plot_height=400)\n",
    "show(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Boolean Search\n",
    "\n",
    "Now we have a tf matrix we can start to use it to find documents that contain words included in a query.  We will start by simply returning the documents from the corpus that match terms in our query and rank by raw term frequency:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_results1(qry, tfm, lexicon):\n",
    "    qrv = [0]*len(lexicon)\n",
    "    for term in qry.split():\n",
    "        if term in lexicon:\n",
    "            qrv[lexicon.index(term)] = 1\n",
    "\n",
    "    results = []      \n",
    "    for i, tfv in enumerate(tfm):\n",
    "        score = sum([x[0] * x[1] for x in zip(tfv, qrv)])\n",
    "        if score > 0:\n",
    "               results.append([score, i])\n",
    "    return results\n",
    "\n",
    "def print_results(results,n, head=True):\n",
    "    if head:    \n",
    "        print('\\nTop %d from recall set of %d items ordered by tf-idf:' % (n,len(results)))\n",
    "        for r in sorted(results, key=lambda t: t[0] * -1 )[:n]:\n",
    "            print('\\t%0.2f - %s'%(r[0],items_t[r[1]]))\n",
    "    else:\n",
    "        print('\\nBottom %d from recall set of %d items ordered by tf-idf:' % (n,len(results)))\n",
    "        for r in sorted(results, key=lambda t: t[0] * 1 )[:n]:\n",
    "            print('\\t%0.2f - %s'%(r[0],items_t[r[1]]))\n",
    "    \n",
    "tfm, lexicon = tfm2(items_t)\n",
    "results = get_results1('front rear back led bike light', tfm , lexicon)\n",
    "\n",
    "print_results(results,10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But this is an expensive operation.  Each query has to be compared to all documents in the corpus.  We can speed this up by creating an inverted index:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def create_inverted_index(corpus):\n",
    "    idx={}\n",
    "    for i, doc in enumerate(corpus):\n",
    "        for word in doc.split():\n",
    "            if word in idx:\n",
    "                idx[word].append(i)\n",
    "            else:\n",
    "                idx[word] = [i]\n",
    "    return idx\n",
    "            \n",
    "idx = create_inverted_index(items_t)\n",
    "\n",
    "print(set(idx['front']).intersection(set(idx['rear'])))\n",
    "print(items_t[7676])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we just have to query for each of the terms and produce a set of results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_results2(qry, idx):\n",
    "\n",
    "    score = Counter()\n",
    "    terms = qry.split()\n",
    "    for term in terms:\n",
    "        for doc in idx[term]:\n",
    "            score[doc] += 1\n",
    "            \n",
    "    results=[]\n",
    "    for x in [[r[0],r[1]] for r in zip(score.keys(), score.values())]:\n",
    "        if x[1] > 0:\n",
    "            # output [0] score, [1] doc_id\n",
    "            results.append([x[1],x[0]])\n",
    "\n",
    "    return results;\n",
    "\n",
    "\n",
    "idx = create_inverted_index(items_t)\n",
    "%timeit results = get_results2('front rear back led bike light', idx)\n",
    "\n",
    "print_results(results,10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We get a lot of documents in the recall set since many match on one of the words - bike is present in almost every other document!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'term':[x for x in idx.keys()],'freq':[len(x) for x in idx.values()]})\n",
    "\n",
    "output_notebook(hide_banner=True)\n",
    "p = Bar(df.sort_values('freq', ascending=False)[:30], label=CatAttr(columns=['term'], sort=False), values='freq',\n",
    "        plot_width=800, plot_height=400)\n",
    "show(p)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inverse Document Frequency (IDF)\n",
    "\n",
    "It would seem sensible to down weight words that are very common in the corpus - the word 'bike' in a query is not as discriminating as the word 'front'. IDF is a way to quantify how common or rare a term is in the corpus.  It is computed by taking the log of the inverse fraction of the number of documents in which the term appears divided by the total number of documents.  To avoid division by zero it is common to add 1 to the number of documents in which the term appears.  \n",
    "\n",
    "IDF is already partially computed when we constructed the inverted index - it is the number of documents the term apears in - in otherwords the length of the document list in the inverted index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def create_inverted_index(corpus):\n",
    "    idx={}\n",
    "    for i, doc in enumerate(corpus):\n",
    "        for word in doc.split():\n",
    "            if word in idx:\n",
    "                if i in idx[word]:\n",
    "                    # Update document's frequency\n",
    "                    idx[word][i] += 1\n",
    "                else:\n",
    "                    # Add document\n",
    "                    idx[word][i] = 1\n",
    "            else:\n",
    "                # Add term\n",
    "                idx[word] = {i:1}\n",
    "    return idx\n",
    "\n",
    "def idf(term, idx, n):\n",
    "    return math.log( float(n) / (1 + len(idx[term])))\n",
    "\n",
    "idx = create_inverted_index(items_t)\n",
    "\n",
    "\n",
    "df = pd.DataFrame({'term':[x for x in idx.keys()],'freq':[len(x) for x in idx.values()],\n",
    "                  'idf':[idf(x, idx, len(items_t)) for x in idx.keys()]})\n",
    "\n",
    "output_notebook(hide_banner=True)\n",
    "p1 = Bar(df.sort_values('freq', ascending=False)[:30], label=CatAttr(columns=['term'], sort=False), values='freq',\n",
    "        plot_width=800, plot_height=400)\n",
    "\n",
    "p2 = Bar(df.sort_values('freq', ascending=False)[:30], label=CatAttr(columns=['term'], sort=False), values='idf',\n",
    "        plot_width=800, plot_height=400)\n",
    "\n",
    "p = vplot(p1, p2)\n",
    "\n",
    "show(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ranking by TF-IDF\n",
    "\n",
    "We can now combine term frequency and inverse document frequency when computing the score for each item in the recall set.  Until now we have just computed the score as the raw frequency of the query terms in each document.  Now we want to weight the raw frequency by the inverse documetn frequency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_results3(qry, idx, n):\n",
    "    score = Counter()\n",
    "    for term in qry.split():\n",
    "        if term in idf:\n",
    "            i = idf(term, idx, n)\n",
    "            for doc in idx[term]:\n",
    "                score[doc] += idx[term][doc] * i\n",
    "        \n",
    "    results=[]\n",
    "    for x in [[r[0],r[1]] for r in zip(score.keys(), score.values())]:\n",
    "        if x[1] > 0:\n",
    "            # output [0] score, [1] doc_id\n",
    "            results.append([x[1],x[0]])\n",
    "\n",
    "    return results;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "idx = create_inverted_index(items_t)\n",
    "results = get_results3('front led bike light', idx, len(items_t))\n",
    "\n",
    "print_results(results,10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problematic queries!\n",
    "\n",
    "With this corpus we cannot search for mountain bikes without returning a heap of accesories:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "idx = create_inverted_index(items_t)\n",
    "results = get_results3('mountain bike', idx, len(items_t))\n",
    "\n",
    "print_results(results,10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to penalise items where there are many more terms in the query.  For example the terms \"mountain\" and \"bike\" only make up 2 / 12 terms in the \"oakley mens automatic mountain mtb factory lite mountain bmx bike gloves large\" yet it scores highly because there is no penalty for all the other terms in the item title.\n",
    "\n",
    "In addition this scheme create discrete levels based on combination of word frequency:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'score':[float(x[0]) for x in results],\n",
    "                   'title':[items_t[x[1]] for x in results]})\n",
    "\n",
    "d = df.groupby('score').first().reset_index()\n",
    "\n",
    "r1 = re.compile('(bike)')\n",
    "r2 = re.compile('(mountain)')\n",
    "\n",
    "for i, t in enumerate(d.title):\n",
    "    n1 = r1.findall(t)\n",
    "    n2 = r2.findall(t)\n",
    "    print('%d x Bike, %d x Mountain, Score = %0.2f'%(len(n1),len(n2),d.score[i]))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Plot score vs item length\n",
    "df = pd.DataFrame({'score':[float(x[0]) for x in results],\n",
    "                   'length':[len(items_t[x[1]].split()) for x in results]})\n",
    "\n",
    "output_notebook(hide_banner=True)\n",
    "p = Scatter(df, x='score', y='length')\n",
    "show(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ideally we do not want scores to be the same for lots of documents.  We could try by boosting the score for documents that are shorter than average."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_results4(qry, corpus):\n",
    "    idx = create_inverted_index(corpus)\n",
    "    n = len(corpus)\n",
    "    d = [len(x.split()) for x in corpus]\n",
    "    d_avg = float(sum(d)) / len(d)\n",
    "    score = Counter()\n",
    "    for term in qry.split():\n",
    "        if term in idf:\n",
    "            i = idf(term, idx, n)\n",
    "            for doc in idx[term]:\n",
    "                f = float(idx[term][doc])\n",
    "                score[doc] += i *  ( f / (float(d[doc]) / d_avg) )\n",
    "        \n",
    "    results=[]\n",
    "    for x in [[r[0],r[1]] for r in zip(score.keys(), score.values())]:\n",
    "        if x[1] > 0:\n",
    "            # output [0] score, [1] doc_id\n",
    "            results.append([x[1],x[0]])\n",
    "\n",
    "    return results;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "results = get_results4('mountain bike', items_t)\n",
    "print_results(results, 10)\n",
    "\n",
    "# Plot score vs item length\n",
    "df = pd.DataFrame({'score':[float(x[0]) for x in results],\n",
    "                   'length':[len(items_t[x[1]].split()) for x in results]})\n",
    "\n",
    "output_notebook()\n",
    "p = Scatter(df, x='score', y='length')\n",
    "show(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Okapi BM25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_results5(qry, corpus, k1=1.5, b=0.75):\n",
    "    idx = create_inverted_index(corpus)\n",
    "    n = len(corpus)\n",
    "    d = [len(x.split()) for x in corpus]\n",
    "    d_avg = float(sum(d)) / len(d)                \n",
    "    score = Counter()\n",
    "    for term in qry.split():\n",
    "        if term in idf:\n",
    "            i = idf(term, idx, n)\n",
    "            for doc in idx[term]:\n",
    "                f = float(idx[term][doc])\n",
    "                score[doc] += i * (( f * (k1 + 1) ) / (f + k1 * (1 - b + (b * (float(d[doc]) / d_avg)))))\n",
    "        \n",
    "    results=[]\n",
    "    for x in [[r[0],r[1]] for r in zip(score.keys(), score.values())]:\n",
    "        if x[1] > 0:\n",
    "            # output [0] score, [1] doc_id\n",
    "            results.append([x[1],x[0]])\n",
    "\n",
    "    return results;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "results = get_results5('mountain bike', items_t)\n",
    "print_results(results, 10)\n",
    "\n",
    "# Plot score vs item length\n",
    "df = pd.DataFrame({'score':[float(x[0]) for x in results],\n",
    "                   'length':[len(items_t[x[1]].split()) for x in results]})\n",
    "\n",
    "output_notebook()\n",
    "p = Scatter(df, x='score', y='length')\n",
    "show(p)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Can we make the above interactive?\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
